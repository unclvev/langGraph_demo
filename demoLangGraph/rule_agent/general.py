# demoLangGraph/service_agent/general.py
import os, requests
from typing import List, Dict
from langchain_core.messages import AIMessage
from langchain_core.prompts import ChatPromptTemplate

from langchain_google_genai import ChatGoogleGenerativeAI

from demoLangGraph.travel_bot.state import AgentState, normalize_messages

# ---------- SerpAPI (tÃ¹y chá»n) ----------
def _serpapi_search(q: str, num: int = 5) -> List[Dict]:
    api_key = os.getenv("SERPAPI_API_KEY")
    if not api_key:
        return []
    try:
        r = requests.get(
            "https://serpapi.com/search.json",
            params={"engine": "google", "q": q, "num": num, "api_key": api_key},
            timeout=8,
        )
        data = r.json()
        out = []
        for item in (data.get("organic_results") or [])[:num]:
            out.append({
                "title": item.get("title", ""),
                "link": item.get("link", ""),
                "snippet": item.get("snippet", "") or (item.get("snippet_highlighted_words") or [""])[0]
            })
        ab = data.get("answer_box") or {}
        if ab.get("answer"):
            out.insert(0, {"title": "TÃ³m táº¯t", "link": "", "snippet": ab["answer"]})
        return out
    except Exception:
        return []

# ---------- LLM (Gemini) ----------
def _llm():
    # Láº¥y model tá»« env, máº·c Ä‘á»‹nh dÃ¹ng gemini-1.5-flash (nhanh, ráº»)
    model = os.getenv("TRAVEL_BOT_MODEL", "gemini-1.5-flash")
    # GOOGLE_API_KEY pháº£i cÃ³ trong env/.env
    return ChatGoogleGenerativeAI(model=model, temperature=0.3)

_RULES = """## Prompt Chatbot Du Lá»‹ch (ThÃ¢n thiá»‡n)
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ¢n thiá»‡n, dÃ­ dá»m, vui tÃ­nh chuyÃªn há»— trá»£ vá» du lá»‹ch.
- Náº¿u ngÆ°á»i dÃ¹ng chÃ o há»i, hÃ£y chÃ o láº¡i thÃ¢n thiá»‡n vÃ  há»i xem há» cáº§n giÃºp gÃ¬ vá» du lá»‹ch.
- Náº¿u ngÆ°á»i dÃ¹ng há»i vá» Ä‘á»‹a danh/Ä‘iá»ƒm vui chÆ¡i/tour/khÃ¡ch sáº¡n/áº©m thá»±c/di chuyá»ƒn,â€¦ hÃ£y tráº£ lá»i rÃµ rÃ ng, chi tiáº¿t vÃ  thÃ¢n thiá»‡n.
- Náº¿u cÃ³ káº¿t quáº£ tá»« SerpAPI (SERP_CONTEXT), hÃ£y diá»…n giáº£i tá»± nhiÃªn; chá»‰ nÃªu link khi tháº­t cáº§n.
- Náº¿u ngoÃ i du lá»‹ch: â€œMÃ¬nh lÃ  trá»£ lÃ½ du lá»‹ch, nÃªn chá»‰ cÃ³ thá»ƒ há»— trá»£ cÃ¡c thÃ´ng tin, tÆ° váº¥n liÃªn quan Ä‘áº¿n du lá»‹ch thÃ´i nhÃ©.â€
- LuÃ´n giá»¯ vÄƒn phong tá»± nhiÃªn, nhiá»‡t tÃ¬nh.
"""

_PROMPT = ChatPromptTemplate.from_messages([
    ("system", _RULES),
    ("system", "SERP_CONTEXT (náº¿u cÃ³):\n{serp_context}"),
    ("human", "{user_query}")
])

def _call_llm_travel(user_query: str, serp_results: List[Dict]) -> str:
    serp_ctx = ""
    if serp_results:
        lines = []
        for r in serp_results[:3]:
            line = f"- {r.get('title','')}: {r.get('snippet','')}"
            if r.get("link"):
                line += f" ({r['link']})"
            lines.append(line)
        serp_ctx = "\n".join(lines)
    chain_input = {"user_query": user_query, "serp_context": serp_ctx}

    # LangChain style: prompt.invoke(...) -> Message, rá»“i llm.invoke(Message)
    msg = _PROMPT.invoke(chain_input)
    return _llm().invoke(msg).content

# ---------- Node GENERAL (router + LLM) ----------
def general_router(state: AgentState) -> AgentState:
    print("[DEBUG] entered general_router")
    messages = normalize_messages(state.get("messages", []))
    user_text = (messages[-1].content or "").strip() if messages else ""
    txt = user_text.lower()

    # 1) chÃ o há»i â†’ tráº£ lá»i nhanh (khÃ´ng cáº§n LLM)
    if any(k in txt for k in ["xin chÃ o", "chÃ o", "hello", "hi"]):
        resp = ("ChÃ o báº¡n! MÃ¬nh lÃ  trá»£ lÃ½ du lá»‹ch "
                "Báº¡n muá»‘n tÃ¬m hiá»ƒu Ä‘á»‹a Ä‘iá»ƒm hay lÃªn káº¿ hoáº¡ch chuyáº¿n Ä‘i nÃ o khÃ´ng?")
    # 2) ngoÃ i du lá»‹ch â†’ tá»« chá»‘i nháº¹
    elif any(k in txt for k in ["chá»©ng khoÃ¡n","coin","crypto","báº¥t Ä‘á»™ng sáº£n","láº­p trÃ¬nh","ai model"]):
        resp = ("MÃ¬nh lÃ  trá»£ lÃ½ du lá»‹ch, nÃªn chá»‰ cÃ³ thá»ƒ há»— trá»£ thÃ´ng tin, tÆ° váº¥n liÃªn quan Ä‘áº¿n du lá»‹ch thÃ´i nhÃ©. "
                "Náº¿u báº¡n cáº§n gá»£i Ã½ Ä‘á»‹a Ä‘iá»ƒm, lá»‹ch trÃ¬nh, khÃ¡ch sáº¡n hay cÃ¡ch di chuyá»ƒn, mÃ¬nh sáºµn sÃ ng giÃºp! ğŸŒ")
    # 3) cÃ²n láº¡i â†’ gá»i SerpAPI (náº¿u cÃ³) + LLM (Gemini)
    else:
        serp = _serpapi_search(user_text, num=5)
        resp = _call_llm_travel(user_text, serp)

    state["messages"] = messages + [AIMessage(content=resp)]
    state["current_step"] = "responded"
    return state
